<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Daixinle的博客">
    <meta name="keyword" content="IT">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        神经网络基础学习 - Daixinle的博客 | Dai&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> Recording my study </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar">
            <img src="/img/avatar.jpg">
        </div>
        <div class="name">
            <i>Xinle Dai</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li>
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li>
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li>
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input">
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>
        <div class="index-about-mobile">
            <i> Recording my study </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        神经网络基础学习
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-03-12 02:03:20</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#人工智能" title="人工智能">人工智能</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#入门知识" title="入门知识">入门知识</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#数学相关" title="数学相关">数学相关</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>

    </div>
    <div class="post-content ">
        <blockquote>
<p>参考博客：<a href="https://blog.csdn.net/lyl771857509/article/details/78990215" target="_blank" rel="noopener">【深度学习】神经网络入门</a></p>
</blockquote>
<ul>
<li><font size="5" face="黑体"><b>人工神经网络登场的前景</b></font><br><font size="4" face="黑体"><br>  假设我们有0.14，0.57，01.29，3.57，5.14这5个点，那么第7个是多少？一眼看上去好像看不出来，假如画个图拟合一下，我们可以看到：<br><br>  <img src="1.png" alt><br><br>  这样我们可以清楚看到，下一个是7。但是，计算机并不会这样画线，所以需要拟合。<br>  这就是回归（曲线拟合）问题。<br>  从最简单的方法开始：<br><br>  <img src="2.png" alt><br><br>  我们初始化一条直线 y=kx+b,然后不断旋转平移调整它，直到它的误差达到最小或者小于某个值（如0.00001）便停止旋转。这就是<b>梯度下降法（Gradient Descent）</b><br>  计算误差，我们用的是最小二乘法。到这里，好像就解决问题了，但是上面那仅仅适用于直线。所以我们需要更加普适的方法。<br>  我们知道，误差的计算：$误差=（直线点-样本点）^2$，那么，假如我们可以找到合适的参数使得误差最小，那么就是找到了答案。<br>  可以看到，误差的函数是二次函数：<br><br>  <img src="3.png" alt><br><br>  那么，我们知道，当这个函数值最小时候，导数最小，那么我们做一个切线，我们就不断旋转这个切线，找到最小的误差。<br><br>  <img src="4.png" alt><br><br>  其中，切线每次旋转的幅度就叫做<b>学习率（learning rate）</b>，求出的切线的斜率叫做<b>导数</b>，假如要求多个曲线的导数，那其中某个曲线的斜率就叫做<b>偏导数</b><br>  这种方法存在的问题是会陷入局部最优解，如下图：<br><br>  <img src="5.png" alt><br><br>  而且，假如维度增加，那么特征数的增加是难以接受的。假如，有一张50*50的灰度图，那么这个图片的维度为50*50=2500，根据公式 $特征数=\frac{维度^2}{2}$，我们可以知道，就这么一个小小的图片，特征数达到了上百万，这明显消耗太大。<br>  所以，就有了<b>神经网络</b>的登场。<br><br></font></li>
<li><font size="5" face="黑体"><b>神经网络中的单个神经元</b></font><br><font size="4" face="黑体"><br>  下图就是单个神经元的基本数学模型：<br><br>  <img src="6.png" alt><br><br>  X1，X2这些输入代表了初始特征，w0，w1这些代表了对应的权重，然后将特征加权求和：<br>  $ res = 1*w0 + X1*w1 + X2*w2 + X3*w3 $<br>  然后还可以看到下一步，将加权求和的结果送入激活函数，激活函数主要有以下几个：<br>  <ol><br>    <li><b>Purelin</b>：<font size="4">$y = x$</font></li><br>    <li><b>Sigmoid</b>：<font size="4">$y = logsig(x) = \frac{1}{1+e^(-x)}$</font></li><br>    <li><b>Tansig </b>：<font size="4">$y = tansig(x) = \frac{e^x - e^(-x)}{e^x + e^(-x)}$</font></li><br>  </ol><br>  后两个函数的图像如下：<br><br>  <img src="7.png" alt><br><br>  可以看到，logsig的范围为0 ~ 1，tansig的范围为-1 ~ 1<br><br></font></li>
<li><font size="5" face="黑体"><b>神经网络</b></font><br><font size="4" face="黑体"><br>  先上几张简单的神经网络的结构图：<br><br>  <img src="8.png" alt><br><br>  <ul><br>    <li> 左边蓝色的，是<b>输入层</b><br>    </li><li> 中间橙色的，是<b>隐藏层</b>，不管多少层，都是隐藏层<br>    </li><li> 右边绿色的，是<b>输出层</b><br>  </li></ul><br>  在这些节点之间的连接线上，是有权重的，计算方法就是和前面一样的加权求和以及激活。<br>  从输入层通过计算传播到隐藏层，再到输出层，最后输出层的结果和样本值比较，得到误差，这个过程就叫做<b>前向传播</b>。<br>  但是，假如采用前面所述的梯度下降法，不断修改参数使得误差最小，那么，在神经网络中，需要修改每条连接线上的权重参数，这是不容易的。<br><br></font></li>
<li><font size="5" face="黑体"><b>BP神经网络</b></font><br><font size="4" face="黑体"><br>  BP反向传播算法的基本思想：利用前向传播最后输出的结果，计算得到误差。然后计算误差的偏导数，再和前面的隐藏层加权求和，如此一层层向后传递，最后到达输入层，用计算出来的偏导数来更新权重。<br>  为了和前向传播的误差区分，这里使用残差来表示误差的偏导数。<br>  残差的计算：<br>  <ol><br>    <li>输出层 -&gt; 隐藏层：$ 残差 = -(输出值 - 样本值)*激活函数的导数 $</li><br>    <li>隐藏层 -&gt; 隐藏层：$ 残差 = -(右层每个节点的残差加权求和)*激活函数的导数 $</li><br>  </ol><br>  对于这个激活函数的导数，对于以下几个我们常用的激活函数：<br>  <ol><br>    <li>Pureline函数：$ Pureline’(x) = 1 $</li><br>    <li>Sigmod函数：$ Sigmod’(x) = Sigmod(x)*(1 - Sigmod(x)) $</li><br>    <li>Tansig函数：$ tansig’(x) = 1 - tansig(x)^2 $</li><br>  </ol><br>  残差计算完之后，就可以更新权重了<br>  <ul><br>    <li>输入层：权重改变量 = 当前节点的激活函数值*右层对应节点的残差*学习率</li><br>    <li>隐藏层：权重改变量 = 输入值*右层节点的残差*学习率</li><br>    <li>偏移值：右层对应节点的残差*学习率</li><br>  </ul><br>  计算举例：<br>  <img src="example_1.png" alt><br>  <img src="example_2.png" alt><br>  <img src="example_3.png" alt><br>  <img src="example_4.png" alt><br>  <img src="example_5.png" alt><br>  <img src="example_6.png" alt><br>  <img src="example_7.png" alt><br></font></li>
</ul>

        
        <br>
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        
        <li>
            <a target="_blank" href="https://www.zhihu.com/people/dai-xin-le-79/activities">
                            <span class="fa-stack fa-lg">
                                 <i class="iconfont icon-zhihu"></i>
                            </span>
            </a>
        </li>
        

        

        

        
        <li>
            <a target="_blank" href="https://github.com/AnselDai">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-github"></i>
                            </span>
            </a>
        </li>
        

        
        <li>
            <a target="_blank" href="https://www.linkedin.com/in/馨乐-戴-a32756159">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-linkedin"></i>
                            </span>
            </a>
        </li>
        

    </ul>
    
    <p>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
